{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3602973",
   "metadata": {},
   "source": [
    "## Æther: Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b7b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cajas/Archivos/tec/semestre_8/tc3002b/tc3002b/aether/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e053705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
    "embedding_model = AutoModel.from_pretrained(\"huggingface/CodeBERTa-small-v1\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d252d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(datasets: list[tuple[str, str]]):\n",
    "    \"\"\"Load dataset more efficiently by reading unique files only once\n",
    "\n",
    "    Args:\n",
    "        datasets (list[tuple[str, str]]): List of tuples containing the path to the labels file and the base directory of the files.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\"id1\", \"id2\", \"plagio\", \"file1\", \"file2\"]\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for labels_path, base_dir in datasets:\n",
    "        labels_path = Path(labels_path)\n",
    "        base_dir = Path(base_dir)\n",
    "\n",
    "        # Validate paths\n",
    "        if not labels_path.exists() or not labels_path.is_file():\n",
    "            raise FileNotFoundError(f\"Labels file not found: {labels_path}\")\n",
    "        if not base_dir.exists() or not base_dir.is_dir():\n",
    "            raise FileNotFoundError(f\"Base directory not found: {base_dir}\")\n",
    "\n",
    "        # Load labels\n",
    "        df2 = pd.read_csv(labels_path)\n",
    "        \n",
    "        # ensure ids are strings\n",
    "        df2[\"id1\"] = df2[\"id1\"].astype(str)\n",
    "        df2[\"id2\"] = df2[\"id2\"].astype(str)\n",
    "\n",
    "        # Ensure label is an integer\n",
    "        df2[\"plagio\"] = df2[\"plagio\"].astype(int)\n",
    "\n",
    "\n",
    "        # Get unique file IDs to load only once\n",
    "        unique_ids = pd.concat([df2[\"id1\"], df2[\"id2\"]]).unique()\n",
    "\n",
    "        # Load files in one pass\n",
    "        files = {}\n",
    "        for file_id in tqdm(unique_ids, desc=\"Loading files\"):\n",
    "            path = base_dir / f\"{file_id}.java\"\n",
    "            if path.exists():\n",
    "                try:\n",
    "                    files[file_id] = path.read_text(encoding=\"utf-8\")\n",
    "                except UnicodeDecodeError:\n",
    "                    files[file_id] = path.read_text(encoding=\"latin-1\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "        # Map files to dataframe\n",
    "        df2[\"file1\"] = df2[\"id1\"].map(files)\n",
    "        df2[\"file2\"] = df2[\"id2\"].map(files)\n",
    "\n",
    "        # Append to main dataframe\n",
    "        df = pd.concat([df, df2[columns]], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_batch(texts, batch_size=16):\n",
    "    \"\"\"Custom embedding function that minimizes GPU transfers\"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Process in batches to avoid OOM issues\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "\n",
    "        # Tokenize on CPU\n",
    "        inputs = tokenizer(\n",
    "            batch_texts, padding=\"longest\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Transfer to GPU only once per batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Get embeddings (no gradient needed)\n",
    "        with torch.no_grad():\n",
    "            outputs = embedding_model(**inputs)\n",
    "\n",
    "        # Use mean pooling of last hidden state as embedding\n",
    "        # Taking mean across token dimension (dim=1)\n",
    "        # embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        \n",
    "        # Use CLS token as embedding\n",
    "        embeddings = outputs.pooler_output\n",
    "\n",
    "        # Move back to CPU and convert to numpy only once per batch\n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "    # Stack all batch results\n",
    "    return np.vstack(all_embeddings) if all_embeddings else np.array([])\n",
    "\n",
    "def embed(text):\n",
    "    \"\"\"Embed a single text input\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = embedding_model(**inputs)\n",
    "\n",
    "    # Use mean pooling of last hidden state as embedding\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1)[0]\n",
    "    return embeddings.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f1abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_dataset(dataset):\n",
    "    \"\"\"Process dataset by embedding unique files only once\"\"\"\n",
    "    # Extract all unique files to embed\n",
    "    all_files = []\n",
    "    file_to_idx = {}\n",
    "\n",
    "    # Create list of unique files\n",
    "    unique_files = set()\n",
    "    for file1, file2 in zip(dataset[\"file1\"], dataset[\"file2\"]):\n",
    "        unique_files.add(file1)\n",
    "        unique_files.add(file2)\n",
    "\n",
    "    # Convert to list and create mapping\n",
    "    all_files = list(unique_files)\n",
    "    file_to_idx = {file: idx for idx, file in enumerate(all_files)}\n",
    "\n",
    "    print(f\"Embedding {len(all_files)} unique files...\")\n",
    "\n",
    "    # Embed all unique files at once\n",
    "    all_embeddings = embed_batch(all_files, 128)\n",
    "\n",
    "    # Create a dict mapping from file content to embedding\n",
    "    file_to_embedding = {file: all_embeddings[idx] for file, idx in file_to_idx.items()}\n",
    "\n",
    "    # Create a map function to add embeddings\n",
    "    def add_embeddings(example):\n",
    "        return {\n",
    "            \"embeddedFile1\": file_to_embedding[example[\"file1\"]],\n",
    "            \"embeddedFile2\": file_to_embedding[example[\"file2\"]],\n",
    "        }\n",
    "\n",
    "    # Use dataset.map() to add the embedded columns\n",
    "    return dataset.map(add_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c03e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for binary classification using ROC curve.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "\n",
    "def evaluate_model(df, threshold=None, balance_classes=True):\n",
    "    if threshold is None:\n",
    "        threshold = find_optimal_threshold(\n",
    "            df[\"plagio\"].values,\n",
    "            df[\"similarity\"].values,\n",
    "        )\n",
    "        print(f\"Optimal threshold: {threshold:.2f}\")\n",
    "\n",
    "    df[\"predicted\"] = df[\"similarity\"].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    report = classification_report(df[\"plagio\"], df[\"predicted\"])\n",
    "    print(report)\n",
    "\n",
    "    cm = confusion_matrix(df[\"plagio\"], df[\"predicted\"])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=[\"Not Plagiarized\", \"Plagiarized\"]\n",
    "    )\n",
    "    disp.plot(\n",
    "        cmap=plt.cm.Blues,\n",
    "        colorbar=False,\n",
    "        ax=plt.gca(),\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the distribution of the similarity scores\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.hist(\n",
    "        df[\"similarity\"], bins=50, alpha=0.7, color=\"blue\", label=\"Similarity Scores\"\n",
    "    )\n",
    "    plt.axvline(threshold, color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Similarity Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of Similarity Scores\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ccbf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 975/975 [00:00<00:00, 29468.82it/s]\n",
      "Loading files: 100%|██████████| 460/460 [00:00<00:00, 28571.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Embedding 1393 unique files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 11/11 [00:18<00:00,  1.64s/it]\n",
      "Map: 100%|██████████| 1371/1371 [00:00<00:00, 10022.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "LABELS_PATH = Path(\"../../labels\")\n",
    "CONPLAG_LABEL_PATH = LABELS_PATH / \"conplag_labels.csv\"\n",
    "IR_PLAG_LABEL_PATH = LABELS_PATH / \"ir_plag_labels.csv\"\n",
    "\n",
    "BASE_DIR = Path(\"../../datasets\")\n",
    "CONPLAG_BASE_DIR = BASE_DIR / \"conplag_preprocesed\"\n",
    "IR_PLAG_BASE_DIR = BASE_DIR / \"ir_plag_preprocessed\"\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df2 = loadDataset(\n",
    "    [(CONPLAG_LABEL_PATH, CONPLAG_BASE_DIR), (IR_PLAG_LABEL_PATH, IR_PLAG_BASE_DIR)]\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_pandas(df2)\n",
    "\n",
    "# Process dataset (embed files)\n",
    "print(\"Processing dataset...\")\n",
    "embedded_dataset = embed_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae73d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset...\n",
      "Train, validation, and test datasets prepared.\n",
      "Length of train set: 1096, Length of validation set: 138, Length of test set: 137\n",
      "Input dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "# 80% train, 10% validation, 10% test\n",
    "print(\"Splitting dataset...\")\n",
    "\n",
    "df2 = embedded_dataset.to_pandas()\n",
    "\n",
    "X = np.array([np.subtract(row[\"embeddedFile1\"], row[\"embeddedFile2\"]) \n",
    "              for _, row in df2.iterrows()], dtype=np.float32)\n",
    "\n",
    "Y = df2[\"plagio\"].values.astype(np.float32)\n",
    "\n",
    "\n",
    "# Split the combined dataset\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train, validation, and test datasets prepared.\")\n",
    "print(f\"Length of train set: {len(Y_train)}, Length of validation set: {len(Y_val)}, Length of test set: {len(Y_test)}\")\n",
    "print(f\"Input dimension: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bee81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 768\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_dim, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(32, 16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(16, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3255291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.3131, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [2/1000], Loss: 0.3046, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [3/1000], Loss: 0.3212, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [4/1000], Loss: 0.3384, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [5/1000], Loss: 0.3227, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [6/1000], Loss: 0.3327, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [7/1000], Loss: 0.3167, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [8/1000], Loss: 0.3327, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [9/1000], Loss: 0.3327, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [10/1000], Loss: 0.3243, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [11/1000], Loss: 0.3083, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [12/1000], Loss: 0.3084, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [13/1000], Loss: 0.3364, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [14/1000], Loss: 0.3190, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [15/1000], Loss: 0.3385, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [16/1000], Loss: 0.3170, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [17/1000], Loss: 0.2982, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [18/1000], Loss: 0.3184, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [19/1000], Loss: 0.3149, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [20/1000], Loss: 0.3295, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [21/1000], Loss: 0.2986, Val Loss: 0.4497, Val Accuracy: 0.8623\n",
      "Epoch [22/1000], Loss: 0.3110, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [23/1000], Loss: 0.3185, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [24/1000], Loss: 0.3235, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [25/1000], Loss: 0.3092, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [26/1000], Loss: 0.3169, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [27/1000], Loss: 0.3304, Val Loss: 0.4496, Val Accuracy: 0.8623\n",
      "Epoch [28/1000], Loss: 0.3208, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [29/1000], Loss: 0.3224, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [30/1000], Loss: 0.3151, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [31/1000], Loss: 0.3198, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [32/1000], Loss: 0.3177, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [33/1000], Loss: 0.3102, Val Loss: 0.4495, Val Accuracy: 0.8623\n",
      "Epoch [34/1000], Loss: 0.3182, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [35/1000], Loss: 0.3390, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [36/1000], Loss: 0.3185, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [37/1000], Loss: 0.3252, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [38/1000], Loss: 0.3248, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [39/1000], Loss: 0.3226, Val Loss: 0.4494, Val Accuracy: 0.8623\n",
      "Epoch [40/1000], Loss: 0.3142, Val Loss: 0.4493, Val Accuracy: 0.8623\n",
      "Epoch [41/1000], Loss: 0.3230, Val Loss: 0.4493, Val Accuracy: 0.8623\n",
      "Epoch [42/1000], Loss: 0.3238, Val Loss: 0.4493, Val Accuracy: 0.8623\n",
      "Epoch [43/1000], Loss: 0.3041, Val Loss: 0.4493, Val Accuracy: 0.8623\n",
      "Epoch [44/1000], Loss: 0.3225, Val Loss: 0.4493, Val Accuracy: 0.8623\n",
      "Epoch [45/1000], Loss: 0.3167, Val Loss: 0.4492, Val Accuracy: 0.8623\n",
      "Epoch [46/1000], Loss: 0.3071, Val Loss: 0.4492, Val Accuracy: 0.8623\n",
      "Epoch [47/1000], Loss: 0.3087, Val Loss: 0.4492, Val Accuracy: 0.8623\n",
      "Epoch [48/1000], Loss: 0.3216, Val Loss: 0.4492, Val Accuracy: 0.8623\n",
      "Epoch [49/1000], Loss: 0.3025, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [50/1000], Loss: 0.3128, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [51/1000], Loss: 0.3246, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [52/1000], Loss: 0.3185, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [53/1000], Loss: 0.3286, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [54/1000], Loss: 0.3187, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [55/1000], Loss: 0.3232, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [56/1000], Loss: 0.3209, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [57/1000], Loss: 0.3130, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [58/1000], Loss: 0.3228, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [59/1000], Loss: 0.3139, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [60/1000], Loss: 0.3217, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [61/1000], Loss: 0.3208, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [62/1000], Loss: 0.3117, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [63/1000], Loss: 0.3181, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [64/1000], Loss: 0.3159, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [65/1000], Loss: 0.3196, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [66/1000], Loss: 0.3191, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [67/1000], Loss: 0.3170, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [68/1000], Loss: 0.3135, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [69/1000], Loss: 0.3346, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [70/1000], Loss: 0.3093, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [71/1000], Loss: 0.3138, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [72/1000], Loss: 0.3283, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [73/1000], Loss: 0.3167, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [74/1000], Loss: 0.3067, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [75/1000], Loss: 0.3083, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [76/1000], Loss: 0.3169, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [77/1000], Loss: 0.3218, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [78/1000], Loss: 0.3238, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [79/1000], Loss: 0.3207, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [80/1000], Loss: 0.3066, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [81/1000], Loss: 0.3258, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [82/1000], Loss: 0.2931, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [83/1000], Loss: 0.3359, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [84/1000], Loss: 0.3083, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [85/1000], Loss: 0.3131, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [86/1000], Loss: 0.3156, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [87/1000], Loss: 0.3284, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [88/1000], Loss: 0.3348, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [89/1000], Loss: 0.3201, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [90/1000], Loss: 0.3236, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [91/1000], Loss: 0.3222, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [92/1000], Loss: 0.3198, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [93/1000], Loss: 0.3258, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [94/1000], Loss: 0.3229, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [95/1000], Loss: 0.3061, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [96/1000], Loss: 0.3292, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [97/1000], Loss: 0.3026, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [98/1000], Loss: 0.3202, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [99/1000], Loss: 0.3175, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [100/1000], Loss: 0.3242, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [101/1000], Loss: 0.3279, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [102/1000], Loss: 0.3153, Val Loss: 0.4491, Val Accuracy: 0.8623\n",
      "Epoch [103/1000], Loss: 0.3096, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [104/1000], Loss: 0.3117, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [105/1000], Loss: 0.3168, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [106/1000], Loss: 0.3016, Val Loss: 0.4490, Val Accuracy: 0.8623\n",
      "Epoch [107/1000], Loss: 0.3177, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [108/1000], Loss: 0.3237, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [109/1000], Loss: 0.3106, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [110/1000], Loss: 0.3066, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [111/1000], Loss: 0.3005, Val Loss: 0.4489, Val Accuracy: 0.8623\n",
      "Epoch [112/1000], Loss: 0.3101, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [113/1000], Loss: 0.3202, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [114/1000], Loss: 0.3094, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [115/1000], Loss: 0.3161, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [116/1000], Loss: 0.2991, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [117/1000], Loss: 0.3190, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [118/1000], Loss: 0.3149, Val Loss: 0.4488, Val Accuracy: 0.8623\n",
      "Epoch [119/1000], Loss: 0.3175, Val Loss: 0.4487, Val Accuracy: 0.8623\n",
      "Epoch [120/1000], Loss: 0.3060, Val Loss: 0.4487, Val Accuracy: 0.8623\n",
      "Epoch [121/1000], Loss: 0.3404, Val Loss: 0.4487, Val Accuracy: 0.8623\n",
      "Epoch [122/1000], Loss: 0.3236, Val Loss: 0.4487, Val Accuracy: 0.8623\n",
      "Epoch [123/1000], Loss: 0.3120, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [124/1000], Loss: 0.3090, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [125/1000], Loss: 0.3082, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [126/1000], Loss: 0.3164, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [127/1000], Loss: 0.2965, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [128/1000], Loss: 0.3015, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [129/1000], Loss: 0.3245, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [130/1000], Loss: 0.3246, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [131/1000], Loss: 0.3214, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [132/1000], Loss: 0.3185, Val Loss: 0.4486, Val Accuracy: 0.8623\n",
      "Epoch [133/1000], Loss: 0.3072, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [134/1000], Loss: 0.3243, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [135/1000], Loss: 0.3088, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [136/1000], Loss: 0.3010, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [137/1000], Loss: 0.3087, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [138/1000], Loss: 0.2957, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [139/1000], Loss: 0.3162, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [140/1000], Loss: 0.3220, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [141/1000], Loss: 0.3232, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [142/1000], Loss: 0.3292, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [143/1000], Loss: 0.3306, Val Loss: 0.4485, Val Accuracy: 0.8623\n",
      "Epoch [144/1000], Loss: 0.3043, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [145/1000], Loss: 0.3084, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [146/1000], Loss: 0.3125, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [147/1000], Loss: 0.3250, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [148/1000], Loss: 0.3215, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [149/1000], Loss: 0.3129, Val Loss: 0.4484, Val Accuracy: 0.8623\n",
      "Epoch [150/1000], Loss: 0.3060, Val Loss: 0.4483, Val Accuracy: 0.8623\n",
      "Epoch [151/1000], Loss: 0.3169, Val Loss: 0.4483, Val Accuracy: 0.8623\n",
      "Epoch [152/1000], Loss: 0.3133, Val Loss: 0.4483, Val Accuracy: 0.8623\n",
      "Epoch [153/1000], Loss: 0.3089, Val Loss: 0.4482, Val Accuracy: 0.8623\n",
      "Epoch [154/1000], Loss: 0.3263, Val Loss: 0.4482, Val Accuracy: 0.8623\n",
      "Epoch [155/1000], Loss: 0.3263, Val Loss: 0.4482, Val Accuracy: 0.8623\n",
      "Epoch [156/1000], Loss: 0.3081, Val Loss: 0.4482, Val Accuracy: 0.8623\n",
      "Epoch [157/1000], Loss: 0.2998, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [158/1000], Loss: 0.3079, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [159/1000], Loss: 0.3147, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [160/1000], Loss: 0.3072, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [161/1000], Loss: 0.3258, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [162/1000], Loss: 0.3064, Val Loss: 0.4481, Val Accuracy: 0.8623\n",
      "Epoch [163/1000], Loss: 0.3033, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [164/1000], Loss: 0.3034, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [165/1000], Loss: 0.3113, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [166/1000], Loss: 0.2984, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [167/1000], Loss: 0.3061, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [168/1000], Loss: 0.2987, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [169/1000], Loss: 0.3020, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [170/1000], Loss: 0.3217, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [171/1000], Loss: 0.3041, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [172/1000], Loss: 0.3309, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [173/1000], Loss: 0.3069, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [174/1000], Loss: 0.3273, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [175/1000], Loss: 0.3076, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [176/1000], Loss: 0.3068, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [177/1000], Loss: 0.3186, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [178/1000], Loss: 0.3074, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [179/1000], Loss: 0.3115, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [180/1000], Loss: 0.3313, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [181/1000], Loss: 0.3091, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [182/1000], Loss: 0.3215, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [183/1000], Loss: 0.3218, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [184/1000], Loss: 0.3254, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [185/1000], Loss: 0.3161, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [186/1000], Loss: 0.3182, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [187/1000], Loss: 0.3160, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [188/1000], Loss: 0.3131, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [189/1000], Loss: 0.3141, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [190/1000], Loss: 0.3114, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [191/1000], Loss: 0.3204, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [192/1000], Loss: 0.3275, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [193/1000], Loss: 0.3149, Val Loss: 0.4480, Val Accuracy: 0.8623\n",
      "Epoch [194/1000], Loss: 0.3095, Val Loss: 0.4479, Val Accuracy: 0.8623\n",
      "Epoch [195/1000], Loss: 0.3158, Val Loss: 0.4479, Val Accuracy: 0.8623\n",
      "Epoch [196/1000], Loss: 0.3070, Val Loss: 0.4479, Val Accuracy: 0.8623\n",
      "Epoch [197/1000], Loss: 0.3390, Val Loss: 0.4479, Val Accuracy: 0.8623\n",
      "Epoch [198/1000], Loss: 0.3155, Val Loss: 0.4479, Val Accuracy: 0.8623\n",
      "Epoch [199/1000], Loss: 0.3025, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [200/1000], Loss: 0.2971, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [201/1000], Loss: 0.3117, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [202/1000], Loss: 0.3150, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [203/1000], Loss: 0.3143, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [204/1000], Loss: 0.3158, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [205/1000], Loss: 0.3248, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [206/1000], Loss: 0.3029, Val Loss: 0.4478, Val Accuracy: 0.8623\n",
      "Epoch [207/1000], Loss: 0.3029, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [208/1000], Loss: 0.2918, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [209/1000], Loss: 0.3057, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [210/1000], Loss: 0.3159, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [211/1000], Loss: 0.3099, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [212/1000], Loss: 0.3064, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [213/1000], Loss: 0.3104, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [214/1000], Loss: 0.3172, Val Loss: 0.4477, Val Accuracy: 0.8623\n",
      "Epoch [215/1000], Loss: 0.3279, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [216/1000], Loss: 0.3149, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [217/1000], Loss: 0.3089, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [218/1000], Loss: 0.3190, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [219/1000], Loss: 0.3008, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [220/1000], Loss: 0.3089, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [221/1000], Loss: 0.2965, Val Loss: 0.4476, Val Accuracy: 0.8623\n",
      "Epoch [222/1000], Loss: 0.3098, Val Loss: 0.4475, Val Accuracy: 0.8623\n",
      "Epoch [223/1000], Loss: 0.3201, Val Loss: 0.4475, Val Accuracy: 0.8623\n",
      "Epoch [224/1000], Loss: 0.3330, Val Loss: 0.4475, Val Accuracy: 0.8623\n",
      "Epoch [225/1000], Loss: 0.3141, Val Loss: 0.4475, Val Accuracy: 0.8623\n",
      "Epoch [226/1000], Loss: 0.3061, Val Loss: 0.4475, Val Accuracy: 0.8623\n",
      "Epoch [227/1000], Loss: 0.2911, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [228/1000], Loss: 0.2992, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [229/1000], Loss: 0.3025, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [230/1000], Loss: 0.3156, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [231/1000], Loss: 0.3237, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [232/1000], Loss: 0.3172, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [233/1000], Loss: 0.3039, Val Loss: 0.4474, Val Accuracy: 0.8623\n",
      "Epoch [234/1000], Loss: 0.3012, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [235/1000], Loss: 0.3139, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [236/1000], Loss: 0.3110, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [237/1000], Loss: 0.3286, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [238/1000], Loss: 0.3023, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [239/1000], Loss: 0.3155, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [240/1000], Loss: 0.3044, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [241/1000], Loss: 0.3081, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [242/1000], Loss: 0.2993, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [243/1000], Loss: 0.3126, Val Loss: 0.4473, Val Accuracy: 0.8623\n",
      "Epoch [244/1000], Loss: 0.2994, Val Loss: 0.4472, Val Accuracy: 0.8623\n",
      "Epoch [245/1000], Loss: 0.3067, Val Loss: 0.4472, Val Accuracy: 0.8623\n",
      "Epoch [246/1000], Loss: 0.3300, Val Loss: 0.4472, Val Accuracy: 0.8623\n",
      "Epoch [247/1000], Loss: 0.3151, Val Loss: 0.4472, Val Accuracy: 0.8623\n",
      "Epoch [248/1000], Loss: 0.3292, Val Loss: 0.4472, Val Accuracy: 0.8623\n",
      "Epoch [249/1000], Loss: 0.3181, Val Loss: 0.4471, Val Accuracy: 0.8623\n",
      "Epoch [250/1000], Loss: 0.3213, Val Loss: 0.4471, Val Accuracy: 0.8623\n",
      "Epoch [251/1000], Loss: 0.3221, Val Loss: 0.4471, Val Accuracy: 0.8623\n",
      "Epoch [252/1000], Loss: 0.3206, Val Loss: 0.4471, Val Accuracy: 0.8623\n",
      "Epoch [253/1000], Loss: 0.2999, Val Loss: 0.4470, Val Accuracy: 0.8623\n",
      "Epoch [254/1000], Loss: 0.3005, Val Loss: 0.4470, Val Accuracy: 0.8623\n",
      "Epoch [255/1000], Loss: 0.3197, Val Loss: 0.4470, Val Accuracy: 0.8623\n",
      "Epoch [256/1000], Loss: 0.3301, Val Loss: 0.4470, Val Accuracy: 0.8623\n",
      "Epoch [257/1000], Loss: 0.3143, Val Loss: 0.4469, Val Accuracy: 0.8623\n",
      "Epoch [258/1000], Loss: 0.3259, Val Loss: 0.4469, Val Accuracy: 0.8623\n",
      "Epoch [259/1000], Loss: 0.3214, Val Loss: 0.4469, Val Accuracy: 0.8623\n",
      "Epoch [260/1000], Loss: 0.3182, Val Loss: 0.4469, Val Accuracy: 0.8623\n",
      "Epoch [261/1000], Loss: 0.3041, Val Loss: 0.4469, Val Accuracy: 0.8623\n",
      "Epoch [262/1000], Loss: 0.3181, Val Loss: 0.4468, Val Accuracy: 0.8623\n",
      "Epoch [263/1000], Loss: 0.3139, Val Loss: 0.4468, Val Accuracy: 0.8623\n",
      "Epoch [264/1000], Loss: 0.3179, Val Loss: 0.4468, Val Accuracy: 0.8623\n",
      "Epoch [265/1000], Loss: 0.3021, Val Loss: 0.4468, Val Accuracy: 0.8623\n",
      "Epoch [266/1000], Loss: 0.3052, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [267/1000], Loss: 0.3140, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [268/1000], Loss: 0.3120, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [269/1000], Loss: 0.3145, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [270/1000], Loss: 0.3023, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [271/1000], Loss: 0.3085, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [272/1000], Loss: 0.3084, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [273/1000], Loss: 0.3340, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [274/1000], Loss: 0.3124, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [275/1000], Loss: 0.3123, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [276/1000], Loss: 0.3224, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [277/1000], Loss: 0.3016, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [278/1000], Loss: 0.3101, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [279/1000], Loss: 0.3198, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [280/1000], Loss: 0.3016, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [281/1000], Loss: 0.3053, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [282/1000], Loss: 0.3144, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [283/1000], Loss: 0.3079, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [284/1000], Loss: 0.2959, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [285/1000], Loss: 0.3223, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [286/1000], Loss: 0.2993, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [287/1000], Loss: 0.3036, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [288/1000], Loss: 0.3176, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [289/1000], Loss: 0.3012, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [290/1000], Loss: 0.3210, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [291/1000], Loss: 0.2851, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [292/1000], Loss: 0.2942, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [293/1000], Loss: 0.3181, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [294/1000], Loss: 0.3163, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [295/1000], Loss: 0.3041, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [296/1000], Loss: 0.3173, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [297/1000], Loss: 0.2889, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [298/1000], Loss: 0.3089, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [299/1000], Loss: 0.3246, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [300/1000], Loss: 0.3099, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [301/1000], Loss: 0.3136, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [302/1000], Loss: 0.2982, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [303/1000], Loss: 0.3077, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [304/1000], Loss: 0.3079, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [305/1000], Loss: 0.3108, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [306/1000], Loss: 0.3184, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [307/1000], Loss: 0.3138, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [308/1000], Loss: 0.3229, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [309/1000], Loss: 0.3000, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [310/1000], Loss: 0.3188, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [311/1000], Loss: 0.3147, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [312/1000], Loss: 0.2991, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [313/1000], Loss: 0.3151, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [314/1000], Loss: 0.3008, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [315/1000], Loss: 0.3083, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [316/1000], Loss: 0.3120, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [317/1000], Loss: 0.2980, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [318/1000], Loss: 0.3006, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [319/1000], Loss: 0.3014, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [320/1000], Loss: 0.3187, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [321/1000], Loss: 0.3107, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [322/1000], Loss: 0.3083, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [323/1000], Loss: 0.2987, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [324/1000], Loss: 0.3244, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [325/1000], Loss: 0.3077, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [326/1000], Loss: 0.2996, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [327/1000], Loss: 0.3086, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [328/1000], Loss: 0.3029, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [329/1000], Loss: 0.3044, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [330/1000], Loss: 0.3023, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [331/1000], Loss: 0.3153, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [332/1000], Loss: 0.2818, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [333/1000], Loss: 0.3132, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [334/1000], Loss: 0.3115, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [335/1000], Loss: 0.3060, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [336/1000], Loss: 0.2996, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [337/1000], Loss: 0.3176, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [338/1000], Loss: 0.3160, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [339/1000], Loss: 0.3113, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [340/1000], Loss: 0.3016, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [341/1000], Loss: 0.3086, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [342/1000], Loss: 0.2958, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [343/1000], Loss: 0.3181, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [344/1000], Loss: 0.3341, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [345/1000], Loss: 0.3047, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [346/1000], Loss: 0.3121, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [347/1000], Loss: 0.3120, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [348/1000], Loss: 0.3119, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [349/1000], Loss: 0.3129, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [350/1000], Loss: 0.3180, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [351/1000], Loss: 0.3115, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [352/1000], Loss: 0.3139, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [353/1000], Loss: 0.3020, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [354/1000], Loss: 0.3029, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [355/1000], Loss: 0.3062, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [356/1000], Loss: 0.3174, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [357/1000], Loss: 0.3225, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [358/1000], Loss: 0.3171, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [359/1000], Loss: 0.3042, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [360/1000], Loss: 0.3170, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [361/1000], Loss: 0.3064, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [362/1000], Loss: 0.2867, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [363/1000], Loss: 0.3094, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [364/1000], Loss: 0.3017, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [365/1000], Loss: 0.2945, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [366/1000], Loss: 0.3072, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [367/1000], Loss: 0.3058, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [368/1000], Loss: 0.3014, Val Loss: 0.4467, Val Accuracy: 0.8623\n",
      "Epoch [369/1000], Loss: 0.3098, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [370/1000], Loss: 0.3153, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [371/1000], Loss: 0.3236, Val Loss: 0.4466, Val Accuracy: 0.8623\n",
      "Epoch [372/1000], Loss: 0.3216, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [373/1000], Loss: 0.3184, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [374/1000], Loss: 0.2843, Val Loss: 0.4465, Val Accuracy: 0.8623\n",
      "Epoch [375/1000], Loss: 0.3006, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [376/1000], Loss: 0.3052, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [377/1000], Loss: 0.3031, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [378/1000], Loss: 0.2947, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [379/1000], Loss: 0.3058, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [380/1000], Loss: 0.3210, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [381/1000], Loss: 0.2979, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [382/1000], Loss: 0.2986, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [383/1000], Loss: 0.3240, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [384/1000], Loss: 0.3220, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [385/1000], Loss: 0.2893, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [386/1000], Loss: 0.3069, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [387/1000], Loss: 0.3010, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [388/1000], Loss: 0.3148, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [389/1000], Loss: 0.3097, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [390/1000], Loss: 0.3022, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [391/1000], Loss: 0.3443, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [392/1000], Loss: 0.2988, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [393/1000], Loss: 0.3086, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [394/1000], Loss: 0.3071, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [395/1000], Loss: 0.3188, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [396/1000], Loss: 0.2931, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [397/1000], Loss: 0.3299, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [398/1000], Loss: 0.3011, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [399/1000], Loss: 0.2924, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [400/1000], Loss: 0.3070, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [401/1000], Loss: 0.3062, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [402/1000], Loss: 0.3012, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [403/1000], Loss: 0.2876, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [404/1000], Loss: 0.3064, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [405/1000], Loss: 0.3053, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [406/1000], Loss: 0.2956, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [407/1000], Loss: 0.3166, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [408/1000], Loss: 0.3011, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [409/1000], Loss: 0.3187, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [410/1000], Loss: 0.3242, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [411/1000], Loss: 0.3213, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [412/1000], Loss: 0.3140, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [413/1000], Loss: 0.2972, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [414/1000], Loss: 0.2998, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [415/1000], Loss: 0.2983, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [416/1000], Loss: 0.3065, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [417/1000], Loss: 0.2968, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [418/1000], Loss: 0.2923, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [419/1000], Loss: 0.3041, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [420/1000], Loss: 0.3313, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [421/1000], Loss: 0.3095, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [422/1000], Loss: 0.3091, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [423/1000], Loss: 0.3106, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [424/1000], Loss: 0.3020, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [425/1000], Loss: 0.3120, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [426/1000], Loss: 0.3025, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [427/1000], Loss: 0.3110, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [428/1000], Loss: 0.3058, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [429/1000], Loss: 0.3013, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [430/1000], Loss: 0.3055, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [431/1000], Loss: 0.3211, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [432/1000], Loss: 0.3044, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [433/1000], Loss: 0.3038, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [434/1000], Loss: 0.3055, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [435/1000], Loss: 0.2922, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [436/1000], Loss: 0.3153, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [437/1000], Loss: 0.2956, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [438/1000], Loss: 0.3069, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [439/1000], Loss: 0.2994, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [440/1000], Loss: 0.2973, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [441/1000], Loss: 0.3086, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [442/1000], Loss: 0.3100, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [443/1000], Loss: 0.3082, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [444/1000], Loss: 0.3044, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [445/1000], Loss: 0.3289, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [446/1000], Loss: 0.2968, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [447/1000], Loss: 0.3190, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [448/1000], Loss: 0.3226, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [449/1000], Loss: 0.3107, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [450/1000], Loss: 0.3110, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [451/1000], Loss: 0.2911, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [452/1000], Loss: 0.2970, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [453/1000], Loss: 0.2944, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [454/1000], Loss: 0.2891, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [455/1000], Loss: 0.3002, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [456/1000], Loss: 0.3038, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [457/1000], Loss: 0.2910, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [458/1000], Loss: 0.3304, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [459/1000], Loss: 0.3010, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [460/1000], Loss: 0.3268, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [461/1000], Loss: 0.2872, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [462/1000], Loss: 0.3048, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [463/1000], Loss: 0.2872, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [464/1000], Loss: 0.3171, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [465/1000], Loss: 0.2979, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [466/1000], Loss: 0.3041, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [467/1000], Loss: 0.3083, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [468/1000], Loss: 0.3037, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [469/1000], Loss: 0.3178, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [470/1000], Loss: 0.3089, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [471/1000], Loss: 0.3084, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [472/1000], Loss: 0.2903, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [473/1000], Loss: 0.2942, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [474/1000], Loss: 0.3007, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [475/1000], Loss: 0.3068, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [476/1000], Loss: 0.3109, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [477/1000], Loss: 0.3116, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [478/1000], Loss: 0.3051, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [479/1000], Loss: 0.3126, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [480/1000], Loss: 0.3050, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [481/1000], Loss: 0.3241, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [482/1000], Loss: 0.3148, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [483/1000], Loss: 0.3009, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [484/1000], Loss: 0.2937, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [485/1000], Loss: 0.2913, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [486/1000], Loss: 0.3083, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [487/1000], Loss: 0.3051, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [488/1000], Loss: 0.2961, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [489/1000], Loss: 0.3153, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [490/1000], Loss: 0.3186, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [491/1000], Loss: 0.3017, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [492/1000], Loss: 0.2961, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [493/1000], Loss: 0.2776, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [494/1000], Loss: 0.2911, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [495/1000], Loss: 0.2957, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [496/1000], Loss: 0.3128, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [497/1000], Loss: 0.3049, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [498/1000], Loss: 0.3058, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [499/1000], Loss: 0.3016, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [500/1000], Loss: 0.3221, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [501/1000], Loss: 0.3022, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [502/1000], Loss: 0.3130, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [503/1000], Loss: 0.3092, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [504/1000], Loss: 0.2920, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [505/1000], Loss: 0.3031, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [506/1000], Loss: 0.3100, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [507/1000], Loss: 0.3033, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [508/1000], Loss: 0.2973, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [509/1000], Loss: 0.3016, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [510/1000], Loss: 0.3031, Val Loss: 0.4452, Val Accuracy: 0.8623\n",
      "Epoch [511/1000], Loss: 0.3030, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [512/1000], Loss: 0.2965, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [513/1000], Loss: 0.3050, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [514/1000], Loss: 0.3054, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [515/1000], Loss: 0.3239, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [516/1000], Loss: 0.3011, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [517/1000], Loss: 0.2857, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [518/1000], Loss: 0.3139, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [519/1000], Loss: 0.3004, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [520/1000], Loss: 0.2977, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [521/1000], Loss: 0.3045, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [522/1000], Loss: 0.3077, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [523/1000], Loss: 0.3000, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [524/1000], Loss: 0.2916, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [525/1000], Loss: 0.2788, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [526/1000], Loss: 0.3069, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [527/1000], Loss: 0.3201, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [528/1000], Loss: 0.2885, Val Loss: 0.4453, Val Accuracy: 0.8623\n",
      "Epoch [529/1000], Loss: 0.3102, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [530/1000], Loss: 0.2947, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [531/1000], Loss: 0.3071, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [532/1000], Loss: 0.2883, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [533/1000], Loss: 0.2959, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [534/1000], Loss: 0.2972, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [535/1000], Loss: 0.3080, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [536/1000], Loss: 0.2828, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [537/1000], Loss: 0.3078, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [538/1000], Loss: 0.3089, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [539/1000], Loss: 0.2919, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [540/1000], Loss: 0.2986, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [541/1000], Loss: 0.2860, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [542/1000], Loss: 0.3143, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [543/1000], Loss: 0.2804, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [544/1000], Loss: 0.3027, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [545/1000], Loss: 0.2912, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [546/1000], Loss: 0.2925, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [547/1000], Loss: 0.3092, Val Loss: 0.4454, Val Accuracy: 0.8623\n",
      "Epoch [548/1000], Loss: 0.3004, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [549/1000], Loss: 0.3042, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [550/1000], Loss: 0.3156, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [551/1000], Loss: 0.2981, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [552/1000], Loss: 0.3107, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [553/1000], Loss: 0.2984, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [554/1000], Loss: 0.3012, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [555/1000], Loss: 0.3005, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [556/1000], Loss: 0.2929, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [557/1000], Loss: 0.3195, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [558/1000], Loss: 0.3050, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [559/1000], Loss: 0.3110, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [560/1000], Loss: 0.3000, Val Loss: 0.4455, Val Accuracy: 0.8623\n",
      "Epoch [561/1000], Loss: 0.3046, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [562/1000], Loss: 0.3017, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [563/1000], Loss: 0.2911, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [564/1000], Loss: 0.3131, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [565/1000], Loss: 0.3007, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [566/1000], Loss: 0.2880, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [567/1000], Loss: 0.2917, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [568/1000], Loss: 0.3088, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [569/1000], Loss: 0.2918, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [570/1000], Loss: 0.3083, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [571/1000], Loss: 0.2925, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [572/1000], Loss: 0.3019, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [573/1000], Loss: 0.2969, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [574/1000], Loss: 0.3098, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [575/1000], Loss: 0.3161, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [576/1000], Loss: 0.2993, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [577/1000], Loss: 0.2915, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [578/1000], Loss: 0.2959, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [579/1000], Loss: 0.2979, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [580/1000], Loss: 0.3105, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [581/1000], Loss: 0.2863, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [582/1000], Loss: 0.2917, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [583/1000], Loss: 0.3002, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [584/1000], Loss: 0.2863, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [585/1000], Loss: 0.2975, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [586/1000], Loss: 0.2948, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [587/1000], Loss: 0.2818, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [588/1000], Loss: 0.2952, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [589/1000], Loss: 0.2942, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [590/1000], Loss: 0.3060, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [591/1000], Loss: 0.2907, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [592/1000], Loss: 0.3055, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [593/1000], Loss: 0.3019, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [594/1000], Loss: 0.2787, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [595/1000], Loss: 0.3065, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [596/1000], Loss: 0.3071, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [597/1000], Loss: 0.2984, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [598/1000], Loss: 0.3079, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [599/1000], Loss: 0.3021, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [600/1000], Loss: 0.2828, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [601/1000], Loss: 0.3032, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [602/1000], Loss: 0.3108, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [603/1000], Loss: 0.3257, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [604/1000], Loss: 0.2957, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [605/1000], Loss: 0.2984, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [606/1000], Loss: 0.3123, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [607/1000], Loss: 0.3058, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [608/1000], Loss: 0.2910, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [609/1000], Loss: 0.2886, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [610/1000], Loss: 0.3042, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [611/1000], Loss: 0.2956, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [612/1000], Loss: 0.2893, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [613/1000], Loss: 0.3006, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [614/1000], Loss: 0.2931, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [615/1000], Loss: 0.3036, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [616/1000], Loss: 0.3081, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [617/1000], Loss: 0.2981, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [618/1000], Loss: 0.3016, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [619/1000], Loss: 0.2990, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [620/1000], Loss: 0.3040, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [621/1000], Loss: 0.2910, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [622/1000], Loss: 0.3010, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [623/1000], Loss: 0.2951, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [624/1000], Loss: 0.2862, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [625/1000], Loss: 0.2987, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [626/1000], Loss: 0.2991, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [627/1000], Loss: 0.3097, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [628/1000], Loss: 0.2992, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [629/1000], Loss: 0.3067, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [630/1000], Loss: 0.2914, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [631/1000], Loss: 0.2921, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [632/1000], Loss: 0.2917, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [633/1000], Loss: 0.2973, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [634/1000], Loss: 0.2895, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [635/1000], Loss: 0.3141, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [636/1000], Loss: 0.2861, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [637/1000], Loss: 0.2862, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [638/1000], Loss: 0.2898, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [639/1000], Loss: 0.2972, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [640/1000], Loss: 0.2894, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [641/1000], Loss: 0.3118, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [642/1000], Loss: 0.2844, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [643/1000], Loss: 0.2893, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [644/1000], Loss: 0.2884, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [645/1000], Loss: 0.3000, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [646/1000], Loss: 0.2879, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [647/1000], Loss: 0.2799, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [648/1000], Loss: 0.3096, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [649/1000], Loss: 0.2891, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [650/1000], Loss: 0.3076, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [651/1000], Loss: 0.2914, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [652/1000], Loss: 0.2825, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [653/1000], Loss: 0.3000, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [654/1000], Loss: 0.2789, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [655/1000], Loss: 0.3056, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [656/1000], Loss: 0.3094, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [657/1000], Loss: 0.3142, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [658/1000], Loss: 0.3126, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [659/1000], Loss: 0.2969, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [660/1000], Loss: 0.3009, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [661/1000], Loss: 0.2833, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [662/1000], Loss: 0.3020, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [663/1000], Loss: 0.3050, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [664/1000], Loss: 0.2942, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [665/1000], Loss: 0.3042, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [666/1000], Loss: 0.3048, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [667/1000], Loss: 0.3095, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [668/1000], Loss: 0.3030, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [669/1000], Loss: 0.2962, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [670/1000], Loss: 0.2905, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [671/1000], Loss: 0.2917, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [672/1000], Loss: 0.3144, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [673/1000], Loss: 0.2963, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [674/1000], Loss: 0.2944, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [675/1000], Loss: 0.2904, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [676/1000], Loss: 0.3186, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [677/1000], Loss: 0.2907, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [678/1000], Loss: 0.2904, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [679/1000], Loss: 0.2895, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [680/1000], Loss: 0.2896, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [681/1000], Loss: 0.2928, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [682/1000], Loss: 0.3054, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [683/1000], Loss: 0.3050, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [684/1000], Loss: 0.3108, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [685/1000], Loss: 0.2991, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [686/1000], Loss: 0.2934, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [687/1000], Loss: 0.2931, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [688/1000], Loss: 0.3236, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [689/1000], Loss: 0.2984, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [690/1000], Loss: 0.2873, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [691/1000], Loss: 0.3023, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [692/1000], Loss: 0.3023, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [693/1000], Loss: 0.3046, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [694/1000], Loss: 0.2994, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [695/1000], Loss: 0.2757, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [696/1000], Loss: 0.2907, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [697/1000], Loss: 0.2897, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [698/1000], Loss: 0.2996, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [699/1000], Loss: 0.3007, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [700/1000], Loss: 0.2931, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [701/1000], Loss: 0.3112, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [702/1000], Loss: 0.2898, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [703/1000], Loss: 0.2858, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [704/1000], Loss: 0.3031, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [705/1000], Loss: 0.3046, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [706/1000], Loss: 0.2901, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [707/1000], Loss: 0.2991, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [708/1000], Loss: 0.2776, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [709/1000], Loss: 0.2994, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [710/1000], Loss: 0.3030, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [711/1000], Loss: 0.2876, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [712/1000], Loss: 0.2735, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [713/1000], Loss: 0.2979, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [714/1000], Loss: 0.3070, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [715/1000], Loss: 0.3130, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [716/1000], Loss: 0.2894, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [717/1000], Loss: 0.2906, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [718/1000], Loss: 0.2931, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [719/1000], Loss: 0.3088, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [720/1000], Loss: 0.3041, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [721/1000], Loss: 0.3044, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [722/1000], Loss: 0.3200, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [723/1000], Loss: 0.3022, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [724/1000], Loss: 0.2868, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [725/1000], Loss: 0.2957, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [726/1000], Loss: 0.2861, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [727/1000], Loss: 0.2837, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [728/1000], Loss: 0.2865, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [729/1000], Loss: 0.2947, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [730/1000], Loss: 0.2863, Val Loss: 0.4456, Val Accuracy: 0.8623\n",
      "Epoch [731/1000], Loss: 0.3040, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [732/1000], Loss: 0.3138, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [733/1000], Loss: 0.3002, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [734/1000], Loss: 0.2923, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [735/1000], Loss: 0.3048, Val Loss: 0.4457, Val Accuracy: 0.8623\n",
      "Epoch [736/1000], Loss: 0.3095, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [737/1000], Loss: 0.3124, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [738/1000], Loss: 0.2935, Val Loss: 0.4458, Val Accuracy: 0.8623\n",
      "Epoch [739/1000], Loss: 0.2906, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [740/1000], Loss: 0.2952, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [741/1000], Loss: 0.3006, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [742/1000], Loss: 0.3134, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [743/1000], Loss: 0.3030, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [744/1000], Loss: 0.2991, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [745/1000], Loss: 0.3005, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [746/1000], Loss: 0.3106, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [747/1000], Loss: 0.2937, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [748/1000], Loss: 0.3028, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [749/1000], Loss: 0.3017, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [750/1000], Loss: 0.3076, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [751/1000], Loss: 0.2960, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [752/1000], Loss: 0.2904, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [753/1000], Loss: 0.2846, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [754/1000], Loss: 0.3067, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [755/1000], Loss: 0.2973, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [756/1000], Loss: 0.2925, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [757/1000], Loss: 0.2905, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [758/1000], Loss: 0.2840, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [759/1000], Loss: 0.3091, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [760/1000], Loss: 0.3093, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [761/1000], Loss: 0.2802, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [762/1000], Loss: 0.2921, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [763/1000], Loss: 0.3183, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [764/1000], Loss: 0.2861, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [765/1000], Loss: 0.3177, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [766/1000], Loss: 0.2886, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [767/1000], Loss: 0.3079, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [768/1000], Loss: 0.2841, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [769/1000], Loss: 0.2795, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [770/1000], Loss: 0.2951, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [771/1000], Loss: 0.2918, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [772/1000], Loss: 0.2993, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [773/1000], Loss: 0.3036, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [774/1000], Loss: 0.2825, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [775/1000], Loss: 0.2964, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [776/1000], Loss: 0.2970, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [777/1000], Loss: 0.3016, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [778/1000], Loss: 0.2927, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [779/1000], Loss: 0.2989, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [780/1000], Loss: 0.3030, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [781/1000], Loss: 0.2859, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [782/1000], Loss: 0.3048, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [783/1000], Loss: 0.2910, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [784/1000], Loss: 0.3055, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [785/1000], Loss: 0.3135, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [786/1000], Loss: 0.2874, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [787/1000], Loss: 0.3004, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [788/1000], Loss: 0.2990, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [789/1000], Loss: 0.2997, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [790/1000], Loss: 0.2795, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [791/1000], Loss: 0.2973, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [792/1000], Loss: 0.3028, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [793/1000], Loss: 0.2897, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [794/1000], Loss: 0.3102, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [795/1000], Loss: 0.2889, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [796/1000], Loss: 0.2850, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [797/1000], Loss: 0.2946, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [798/1000], Loss: 0.3120, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [799/1000], Loss: 0.2904, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [800/1000], Loss: 0.2860, Val Loss: 0.4459, Val Accuracy: 0.8623\n",
      "Epoch [801/1000], Loss: 0.2839, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [802/1000], Loss: 0.3056, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [803/1000], Loss: 0.2859, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [804/1000], Loss: 0.2799, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [805/1000], Loss: 0.2767, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [806/1000], Loss: 0.3038, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [807/1000], Loss: 0.2798, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [808/1000], Loss: 0.2926, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [809/1000], Loss: 0.3018, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [810/1000], Loss: 0.2892, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [811/1000], Loss: 0.3028, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [812/1000], Loss: 0.3056, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [813/1000], Loss: 0.2960, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [814/1000], Loss: 0.2998, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [815/1000], Loss: 0.2940, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [816/1000], Loss: 0.2735, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [817/1000], Loss: 0.3064, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [818/1000], Loss: 0.2745, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [819/1000], Loss: 0.2922, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [820/1000], Loss: 0.2990, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [821/1000], Loss: 0.3020, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [822/1000], Loss: 0.2886, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [823/1000], Loss: 0.2892, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [824/1000], Loss: 0.2959, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [825/1000], Loss: 0.2959, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [826/1000], Loss: 0.2920, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [827/1000], Loss: 0.3106, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [828/1000], Loss: 0.2969, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [829/1000], Loss: 0.2903, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [830/1000], Loss: 0.3091, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [831/1000], Loss: 0.2898, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [832/1000], Loss: 0.2843, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [833/1000], Loss: 0.2969, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [834/1000], Loss: 0.3055, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [835/1000], Loss: 0.2801, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [836/1000], Loss: 0.2917, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [837/1000], Loss: 0.2903, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [838/1000], Loss: 0.3045, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [839/1000], Loss: 0.2946, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [840/1000], Loss: 0.2953, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [841/1000], Loss: 0.2771, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [842/1000], Loss: 0.3053, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [843/1000], Loss: 0.2858, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [844/1000], Loss: 0.2847, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [845/1000], Loss: 0.2963, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [846/1000], Loss: 0.2844, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [847/1000], Loss: 0.2943, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [848/1000], Loss: 0.3017, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [849/1000], Loss: 0.2941, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [850/1000], Loss: 0.2980, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [851/1000], Loss: 0.2924, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [852/1000], Loss: 0.2781, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [853/1000], Loss: 0.3162, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [854/1000], Loss: 0.3022, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [855/1000], Loss: 0.2878, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [856/1000], Loss: 0.2868, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [857/1000], Loss: 0.2861, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [858/1000], Loss: 0.2842, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [859/1000], Loss: 0.2783, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [860/1000], Loss: 0.2757, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [861/1000], Loss: 0.2983, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [862/1000], Loss: 0.2860, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [863/1000], Loss: 0.2884, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [864/1000], Loss: 0.2931, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [865/1000], Loss: 0.2921, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [866/1000], Loss: 0.2985, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [867/1000], Loss: 0.2934, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [868/1000], Loss: 0.2998, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [869/1000], Loss: 0.2875, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [870/1000], Loss: 0.2920, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [871/1000], Loss: 0.3037, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [872/1000], Loss: 0.2821, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [873/1000], Loss: 0.2752, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [874/1000], Loss: 0.2894, Val Loss: 0.4464, Val Accuracy: 0.8623\n",
      "Epoch [875/1000], Loss: 0.2904, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [876/1000], Loss: 0.2979, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [877/1000], Loss: 0.2891, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [878/1000], Loss: 0.3021, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [879/1000], Loss: 0.2935, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [880/1000], Loss: 0.2816, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [881/1000], Loss: 0.2931, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [882/1000], Loss: 0.2968, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [883/1000], Loss: 0.2853, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [884/1000], Loss: 0.2889, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [885/1000], Loss: 0.2915, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [886/1000], Loss: 0.2891, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [887/1000], Loss: 0.2787, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [888/1000], Loss: 0.2902, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [889/1000], Loss: 0.2904, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [890/1000], Loss: 0.2851, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [891/1000], Loss: 0.2893, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [892/1000], Loss: 0.2933, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [893/1000], Loss: 0.2799, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [894/1000], Loss: 0.2760, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [895/1000], Loss: 0.2975, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [896/1000], Loss: 0.2951, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [897/1000], Loss: 0.2934, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [898/1000], Loss: 0.2990, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [899/1000], Loss: 0.2882, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [900/1000], Loss: 0.2926, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [901/1000], Loss: 0.2801, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [902/1000], Loss: 0.2964, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [903/1000], Loss: 0.2977, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [904/1000], Loss: 0.2797, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [905/1000], Loss: 0.3116, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [906/1000], Loss: 0.2736, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [907/1000], Loss: 0.3001, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [908/1000], Loss: 0.2936, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [909/1000], Loss: 0.2912, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [910/1000], Loss: 0.2830, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [911/1000], Loss: 0.2774, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [912/1000], Loss: 0.2866, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [913/1000], Loss: 0.2955, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [914/1000], Loss: 0.2729, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [915/1000], Loss: 0.2923, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [916/1000], Loss: 0.2845, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [917/1000], Loss: 0.2976, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [918/1000], Loss: 0.2949, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [919/1000], Loss: 0.3004, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [920/1000], Loss: 0.2846, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [921/1000], Loss: 0.2990, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [922/1000], Loss: 0.2983, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [923/1000], Loss: 0.2811, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [924/1000], Loss: 0.3024, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [925/1000], Loss: 0.3017, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [926/1000], Loss: 0.2853, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [927/1000], Loss: 0.3019, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [928/1000], Loss: 0.2805, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [929/1000], Loss: 0.2841, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [930/1000], Loss: 0.2930, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [931/1000], Loss: 0.2931, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [932/1000], Loss: 0.2750, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [933/1000], Loss: 0.2851, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [934/1000], Loss: 0.2940, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [935/1000], Loss: 0.2859, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [936/1000], Loss: 0.2828, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [937/1000], Loss: 0.2951, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [938/1000], Loss: 0.2987, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [939/1000], Loss: 0.2902, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [940/1000], Loss: 0.2858, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [941/1000], Loss: 0.3053, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [942/1000], Loss: 0.2808, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [943/1000], Loss: 0.3044, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [944/1000], Loss: 0.2886, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [945/1000], Loss: 0.2969, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [946/1000], Loss: 0.3068, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [947/1000], Loss: 0.2761, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [948/1000], Loss: 0.2879, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [949/1000], Loss: 0.2862, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [950/1000], Loss: 0.2791, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [951/1000], Loss: 0.2761, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [952/1000], Loss: 0.2832, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [953/1000], Loss: 0.2830, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [954/1000], Loss: 0.3060, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [955/1000], Loss: 0.2868, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [956/1000], Loss: 0.2895, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [957/1000], Loss: 0.2904, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [958/1000], Loss: 0.2857, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [959/1000], Loss: 0.2822, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [960/1000], Loss: 0.2732, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [961/1000], Loss: 0.2958, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [962/1000], Loss: 0.2861, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [963/1000], Loss: 0.2976, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [964/1000], Loss: 0.2943, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [965/1000], Loss: 0.2796, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [966/1000], Loss: 0.3003, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [967/1000], Loss: 0.2749, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [968/1000], Loss: 0.2745, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [969/1000], Loss: 0.2733, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [970/1000], Loss: 0.2847, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [971/1000], Loss: 0.2813, Val Loss: 0.4460, Val Accuracy: 0.8623\n",
      "Epoch [972/1000], Loss: 0.2794, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [973/1000], Loss: 0.2920, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [974/1000], Loss: 0.2875, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [975/1000], Loss: 0.2805, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [976/1000], Loss: 0.2852, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [977/1000], Loss: 0.2841, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [978/1000], Loss: 0.2972, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [979/1000], Loss: 0.2640, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [980/1000], Loss: 0.2913, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [981/1000], Loss: 0.2750, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [982/1000], Loss: 0.2944, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [983/1000], Loss: 0.2879, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [984/1000], Loss: 0.2897, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [985/1000], Loss: 0.2697, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [986/1000], Loss: 0.2949, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [987/1000], Loss: 0.2865, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [988/1000], Loss: 0.2890, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [989/1000], Loss: 0.2930, Val Loss: 0.4461, Val Accuracy: 0.8623\n",
      "Epoch [990/1000], Loss: 0.3048, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [991/1000], Loss: 0.2983, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [992/1000], Loss: 0.2745, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [993/1000], Loss: 0.2772, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [994/1000], Loss: 0.2827, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [995/1000], Loss: 0.2937, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [996/1000], Loss: 0.2965, Val Loss: 0.4463, Val Accuracy: 0.8623\n",
      "Epoch [997/1000], Loss: 0.2834, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [998/1000], Loss: 0.2749, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [999/1000], Loss: 0.2826, Val Loss: 0.4462, Val Accuracy: 0.8623\n",
      "Epoch [1000/1000], Loss: 0.2844, Val Loss: 0.4462, Val Accuracy: 0.8623\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 4096\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = torch.tensor(X_train[i : i + batch_size]).to(device)\n",
    "        batch_Y = torch.tensor(Y_train[i : i + batch_size]).to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_X = torch.tensor(X_val).to(device)\n",
    "        val_Y = torch.tensor(Y_val).to(device).unsqueeze(1)\n",
    "        val_outputs = model(val_X)\n",
    "        val_loss = criterion(val_outputs, val_Y)\n",
    "        val_predictions = (val_outputs > 0.5).float()\n",
    "        val_accuracy = (val_predictions == val_Y).float().mean()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b20186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86        73\n",
      "           1       0.90      0.72      0.80        64\n",
      "\n",
      "    accuracy                           0.83       137\n",
      "   macro avg       0.85      0.83      0.83       137\n",
      "weighted avg       0.84      0.83      0.83       137\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_X = torch.tensor(X_test).to(device)\n",
    "    test_Y = torch.tensor(Y_test).to(device).unsqueeze(1)\n",
    "    outputs = model(test_X)\n",
    "    Y_test = Y_test.astype(int)\n",
    "    df_test = pd.DataFrame({\"plagio\": Y_test, \"similarity\": outputs.cpu().numpy().flatten()})\n",
    "\n",
    "evaluate_model(df_test, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
