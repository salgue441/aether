{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f2ef9f",
   "metadata": {},
   "source": [
    "# Abstract Syntax Tree (AST) Preprocessing for Machine Learning Models\n",
    "Converting source code into a format suitable for machine learning models requires several transformation steps. This document outlines the comprehensive preprocessing pipeline that transforms raw code into vectorized representations that machine learning models can process effectively.\n",
    "\n",
    "## Key Components\n",
    "1. AST Flattening\n",
    "   1. The `flatten_ast` function captures both node types and structural information\n",
    "   2. Tracks parent-child relationships via the path parameter\n",
    "   3. Extracts values from nodes when available\n",
    "2. Tokenization Strategy\n",
    "   1. Creates three types of tokens:\n",
    "      1. Node type tokens (`TYPE_X`)\n",
    "      2. Structural relationship tokens (`PARENT_X_TO_Y`)\n",
    "      3. Value tokens for identifiers and literals (`VAL_X` or `LIT_type`)\n",
    "   2. This preserves both syntactic structure and semantic information\n",
    "3. Vectorization Options\n",
    "   1. Two complementary approaches:\n",
    "      1. Sequence-based: Preserves order of AST nodes using vocabulary mapping\n",
    "      2. Bag-of-nodes: Creates frequency-based vector representations, useful for classification tasks\n",
    "4. Vocabulary Management:\n",
    "   1. Creates a vocabulary with frequency thresholding\n",
    "   2. Includes special tokens for padding and unknown tokens\n",
    "   3. Enables consistent encoding across different code samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "150b24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import javalang\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1483570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code_file(file_path):\n",
    "    \"\"\"Read code from a file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7e20859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ast(code):\n",
    "    \"\"\"\n",
    "    Creates an Abstract Syntax Tree (AST) from the given code.\n",
    "\n",
    "    Args:\n",
    "        code (str): The code to parse.\n",
    "\n",
    "    Returns:\n",
    "        javalang.tree.CompilationUnit: The AST of the code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = javalang.parse.parse(code)\n",
    "        return tree\n",
    "    except javalang.parser.JavaSyntaxError as e:\n",
    "        print(f\"Syntax error in code: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68c45db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def ast_to_xml(node, parent_elem=None):\n",
    "    \"\"\"\n",
    "    Converts an AST node to XML format.\n",
    "\n",
    "    Args:\n",
    "        node: The current AST node\n",
    "        parent_elem: The parent XML element\n",
    "\n",
    "    Returns:\n",
    "        xml.etree.ElementTree.Element: Root element of the XML tree\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return None\n",
    "\n",
    "    # Create root element if this is the first call\n",
    "    if parent_elem is None:\n",
    "        root = ET.Element(\"ast\")\n",
    "    else:\n",
    "        root = parent_elem\n",
    "\n",
    "    # Create element for current node\n",
    "    node_type = node.__class__.__name__\n",
    "    elem = ET.SubElement(root, node_type)\n",
    "\n",
    "    # Add attributes if they exist\n",
    "    if hasattr(node, \"name\"):\n",
    "        elem.set(\"name\", str(node.name))\n",
    "    if hasattr(node, \"value\"):\n",
    "        elem.set(\"value\", str(node.value))\n",
    "\n",
    "    # Process children\n",
    "    if hasattr(node, \"children\"):\n",
    "        for child in node.children:\n",
    "            if isinstance(child, list):\n",
    "                list_elem = ET.SubElement(elem, \"list\")\n",
    "                for item in child:\n",
    "                    if hasattr(item, \"__class__\"):\n",
    "                        ast_to_xml(item, list_elem)\n",
    "            elif hasattr(child, \"__class__\"):\n",
    "                ast_to_xml(child, elem)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37deabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the process_dataset function to use XML conversion\n",
    "def process_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Process all files in the dataset and convert ASTs to XML.\n",
    "\n",
    "    Args:\n",
    "        dataset_path: Path to the dataset directory\n",
    "\n",
    "    Returns:\n",
    "        List of XML strings representing the ASTs\n",
    "    \"\"\"\n",
    "    all_xml_asts = []\n",
    "\n",
    "    for file in os.listdir(dataset_path):\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        code = read_code_file(file_path)\n",
    "\n",
    "        if code:\n",
    "            tree = create_ast(code)\n",
    "            if tree:\n",
    "                xml_tree = ast_to_xml(tree)\n",
    "                xml_string = ET.tostring(xml_tree, encoding=\"unicode\", method=\"xml\")\n",
    "                all_xml_asts.append(xml_string)\n",
    "            else:\n",
    "                print(f\"Failed to create AST for {file}.\")\n",
    "        else:\n",
    "            print(f\"Failed to read code from {file}.\")\n",
    "\n",
    "    return all_xml_asts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "586148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified save function to save XML data\n",
    "def save_processed_data(data, output_file):\n",
    "    \"\"\"Save processed XML data to disk.\"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for xml_ast in data:\n",
    "            f.write(xml_ast + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708e2b0",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0723090",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../datasets/conplag_preprocessed\"\n",
    "processed_data = process_dataset(dataset_path)\n",
    "save_processed_data(processed_data, \"ast_xml_data.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
