{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3602973",
   "metadata": {},
   "source": [
    "## Ã†ther: Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e053705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d252d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(datasets: list[tuple[str, str]]):\n",
    "    \"\"\"Load dataset more efficiently by reading unique files only once\n",
    "\n",
    "    Args:\n",
    "        datasets (list[tuple[str, str]]): List of tuples containing the path to the labels file and the base directory of the files.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\"id1\", \"id2\", \"plagio\", \"file1\", \"file2\"]\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for labels_path, base_dir in datasets:\n",
    "        labels_path = Path(labels_path)\n",
    "        base_dir = Path(base_dir)\n",
    "\n",
    "        # Validate paths\n",
    "        if not labels_path.exists() or not labels_path.is_file():\n",
    "            raise FileNotFoundError(f\"Labels file not found: {labels_path}\")\n",
    "        if not base_dir.exists() or not base_dir.is_dir():\n",
    "            raise FileNotFoundError(f\"Base directory not found: {base_dir}\")\n",
    "\n",
    "        # Load labels\n",
    "        df2 = pd.read_csv(labels_path)\n",
    "        \n",
    "        # ensure ids are strings\n",
    "        df2[\"id1\"] = df2[\"id1\"].astype(str)\n",
    "        df2[\"id2\"] = df2[\"id2\"].astype(str)\n",
    "\n",
    "        # Ensure label is an integer\n",
    "        df2[\"plagio\"] = df2[\"plagio\"].astype(int)\n",
    "\n",
    "\n",
    "        # Get unique file IDs to load only once\n",
    "        unique_ids = pd.concat([df2[\"id1\"], df2[\"id2\"]]).unique()\n",
    "\n",
    "        # Load files in one pass\n",
    "        files = {}\n",
    "        for file_id in tqdm(unique_ids, desc=\"Loading files\"):\n",
    "            path = base_dir / f\"{file_id}.java\"\n",
    "            if path.exists():\n",
    "                try:\n",
    "                    files[file_id] = path.read_text(encoding=\"utf-8\")\n",
    "                except UnicodeDecodeError:\n",
    "                    files[file_id] = path.read_text(encoding=\"latin-1\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "        # Map files to dataframe\n",
    "        df2[\"file1\"] = df2[\"id1\"].map(files)\n",
    "        df2[\"file2\"] = df2[\"id2\"].map(files)\n",
    "\n",
    "        # Append to main dataframe\n",
    "        df = pd.concat([df, df2[columns]], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for binary classification using ROC curve.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "\n",
    "def evaluate_model(df, threshold=None, balance_classes=True):\n",
    "    if threshold is None:\n",
    "        threshold = find_optimal_threshold(\n",
    "            df[\"plagio\"].values,\n",
    "            df[\"similarity\"].values,\n",
    "        )\n",
    "        print(f\"Optimal threshold: {threshold:.2f}\")\n",
    "\n",
    "    df[\"predicted\"] = df[\"similarity\"].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "    report = classification_report(df[\"plagio\"], df[\"predicted\"])\n",
    "    print(report)\n",
    "\n",
    "    cm = confusion_matrix(df[\"plagio\"], df[\"predicted\"])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=[\"Not Plagiarized\", \"Plagiarized\"]\n",
    "    )\n",
    "    disp.plot(\n",
    "        cmap=plt.cm.Blues,\n",
    "        colorbar=False,\n",
    "        ax=plt.gca(),\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the distribution of the similarity scores\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.hist(\n",
    "        df[\"similarity\"], bins=50, alpha=0.7, color=\"blue\", label=\"Similarity Scores\"\n",
    "    )\n",
    "    plt.axvline(threshold, color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Similarity Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of Similarity Scores\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be84fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listOfDictToDictOfTensor(list_of_dicts):\n",
    "    \"\"\"\n",
    "    Convert a list of dictionaries to a dictionary of tensors.\n",
    "    \"\"\"\n",
    "    keys = list_of_dicts[0].keys()\n",
    "    dict_of_tensors = {key: [] for key in keys}\n",
    "\n",
    "    for d in list_of_dicts:\n",
    "        for key in keys:\n",
    "            dict_of_tensors[key].append(d[key])\n",
    "\n",
    "    for key in keys:\n",
    "        # Convert the list of numpy arrays to a single numpy array, then to a tensor\n",
    "        dict_of_tensors[key] = torch.tensor(np.array(dict_of_tensors[key]), device=device)\n",
    "\n",
    "    return dict_of_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "LABELS_PATH = Path(\"../labels\")\n",
    "CONPLAG_LABEL_PATH = LABELS_PATH / \"conplag_labels.csv\"\n",
    "IR_PLAG_LABEL_PATH = LABELS_PATH / \"ir_plag_labels.csv\"\n",
    "\n",
    "BASE_DIR = Path(\"../datasets\")\n",
    "CONPLAG_BASE_DIR = BASE_DIR / \"conplag_preprocesed\"\n",
    "IR_PLAG_BASE_DIR = BASE_DIR / \"ir_plag_preprocessed\"\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df2 = loadDataset(\n",
    "    [(CONPLAG_LABEL_PATH, CONPLAG_BASE_DIR), (IR_PLAG_LABEL_PATH, IR_PLAG_BASE_DIR)]\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_pandas(df2)\n",
    "\n",
    "# Process dataset (tokenize files)\n",
    "print(\"Processing dataset...\")\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokenized1 = tokenizer(\n",
    "        example[\"file1\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    tokenized2 = tokenizer(\n",
    "        example[\"file2\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    return {\n",
    "        \"tokenized1\": tokenized1,\n",
    "        \"tokenized2\": tokenized2,\n",
    "    }\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    ")\n",
    "\n",
    "df = tokenized_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "# 80% train, 10% validation, 10% test\n",
    "print(\"Splitting dataset...\")\n",
    "\n",
    "\n",
    "X1 = [row[\"tokenized1\"] for _, row in df.iterrows()]\n",
    "X2 = [row[\"tokenized2\"] for _, row in df.iterrows()]\n",
    "\n",
    "Y = df[\"plagio\"].values.astype(np.float32)\n",
    "\n",
    "\n",
    "# Split the combined dataset\n",
    "X1_train, X1_temp, Y_train, Y_temp = train_test_split(X1, Y, test_size=0.2, random_state=42)\n",
    "X1_test, X1_val, Y_test, Y_val = train_test_split(X1_temp, Y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "X2_train, X2_temp = train_test_split(X2, test_size=0.2, random_state=42)\n",
    "X2_test, X2_val = train_test_split(X2_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train, validation, and test datasets prepared.\")\n",
    "print(f\"Length of train set: {len(Y_train)}, Length of validation set: {len(Y_val)}, Length of test set: {len(Y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bee81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding model\n",
    "        self.embedding_model = AutoModel.from_pretrained(\n",
    "            \"huggingface/CodeBERTa-small-v1\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = torch.nn.Linear(768, 32)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.6)\n",
    "        self.fc2 = torch.nn.Linear(32, 16)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.dropout2 = torch.nn.Dropout(0.6)\n",
    "        self.fc3 = torch.nn.Linear(16, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        with torch.no_grad():\n",
    "            x1 = self.embedding_model(**x1).pooler_output\n",
    "            x2 = self.embedding_model(**x2).pooler_output\n",
    "        \n",
    "        x = torch.subtract(x1, x2)\n",
    "        x = self.classifier_forward(x)\n",
    "        return x\n",
    "\n",
    "    def classifier_forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062323a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_df = pd.read_csv(\"history.csv\")\n",
    "# if history_df.empty:\n",
    "#     history_df = pd.DataFrame(columns=[ \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"])\n",
    "\n",
    "# for row in history_df.iterrows():\n",
    "#     history.append(\n",
    "#         {\n",
    "#             \"loss\": row[1][\"loss\"],\n",
    "#             \"acc\": row[1][\"acc\"],\n",
    "#             \"val_loss\": row[1][\"val_loss\"],\n",
    "#             \"val_acc\": row[1][\"val_acc\"],\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "# # Load model\n",
    "# model_path = Path(\"model_epoch_60.pth\")\n",
    "# if model_path.exists():\n",
    "#     print(f\"Loading model from {model_path}\")\n",
    "#     model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe87627",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch = 0\n",
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3255291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_Y = torch.from_numpy(Y_train).unsqueeze(1).cpu().numpy()\n",
    "val_Y = torch.from_numpy(Y_val).unsqueeze(1).cpu().numpy()\n",
    "\n",
    "for epoch in range(starting_epoch, num_epochs):\n",
    "    model.train()\n",
    "    curr = {}\n",
    "    acc_loss = []\n",
    "    outputs_acc = []\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for i in tqdm(range(0, len(Y_train), batch_size), desc=\"Training Batch\"):\n",
    "        batch_X1 = listOfDictToDictOfTensor(X1_train[i : i + batch_size])\n",
    "        batch_X2 = listOfDictToDictOfTensor(X2_train[i : i + batch_size])\n",
    "        batch_Y = torch.from_numpy(Y_train[i : i + batch_size]).to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc_loss.append(loss.item())\n",
    "        outputs_acc.append(outputs)\n",
    "\n",
    "    curr[\"loss\"] = np.mean(acc_loss)\n",
    "    outputs_acc = np.concat([out.detach().cpu().numpy() for out in outputs_acc], axis=0)\n",
    "    train_predictions = (outputs_acc > 0.5).astype(int)\n",
    "    train_accuracy = (train_predictions == train_Y).mean()\n",
    "    curr[\"acc\"] = train_accuracy.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f\"model4_epoch_{epoch + 1}.pth\")\n",
    "        print(f\"Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs_acc = []\n",
    "        for i in tqdm(range(0, len(Y_val), batch_size), desc=\"Validating Batch\"):\n",
    "            batch_X1 = listOfDictToDictOfTensor(X1_val[i : i + batch_size])\n",
    "            batch_X2 = listOfDictToDictOfTensor(X2_val[i : i + batch_size])\n",
    "            batch_Y = torch.from_numpy(Y_val[i : i + batch_size]).to(device).unsqueeze(1)\n",
    "            val_outputs = model(batch_X1, batch_X2)\n",
    "            val_outputs_acc.append(val_outputs.cpu().numpy())\n",
    "        val_outputs_acc = np.concatenate(val_outputs_acc, axis=0)\n",
    "        val_loss = criterion(\n",
    "            torch.from_numpy(val_outputs_acc).to(device),\n",
    "            torch.from_numpy(Y_val).to(device).unsqueeze(1),\n",
    "        )\n",
    "        val_predictions = (val_outputs_acc > 0.5).astype(int)\n",
    "        val_accuracy = (val_predictions == val_Y).mean()\n",
    "\n",
    "    curr[\"val_loss\"] = val_loss.item()\n",
    "    curr[\"val_acc\"] = val_accuracy.item()\n",
    "\n",
    "    history.append(curr)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {curr['loss']:.4f}, Acc: {curr['acc']:.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy.item():.4f}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa93ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE HISTORY\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(\"history.csv\", index=False)\n",
    "print(\"Training complete. History saved to history.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552993d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [ x[\"acc\"] for x in history ]\n",
    "val_acc = [ x[\"val_acc\"] for x in history ]\n",
    "loss = [ x[\"loss\"] for x in history ]\n",
    "val_loss = [ x[\"val_loss\"] for x in history ]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, label=\"Train Accuracy\")\n",
    "plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "plt.title(\"Train and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Train and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b20186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs_acc = []\n",
    "    for i in tqdm(range(0, len(Y_test), batch_size), desc=\"Testing Batch\"):\n",
    "        batch_X1 = listOfDictToDictOfTensor(X1_test[i : i + batch_size])\n",
    "        batch_X2 = listOfDictToDictOfTensor(X2_test[i : i + batch_size])\n",
    "        batch_Y = torch.from_numpy(Y_test[i : i + batch_size]).to(device).unsqueeze(1)\n",
    "\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        outputs_acc.append(outputs.cpu().numpy())\n",
    "    outputs_acc = np.concatenate(outputs_acc, axis=0)\n",
    "    \n",
    "    test_Y = torch.from_numpy(Y_test).unsqueeze(1).cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "    {\n",
    "        \"similarity\": outputs_acc.flatten(),\n",
    "        \"plagio\": test_Y.flatten(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8572969",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df_test, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a54cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs_acc = []\n",
    "    for i in tqdm(range(0, len(Y_train), batch_size), desc=\"Testing Batch\"):\n",
    "        batch_X1 = listOfDictToDictOfTensor(X1_train[i : i + batch_size])\n",
    "        batch_X2 = listOfDictToDictOfTensor(X2_train[i : i + batch_size])\n",
    "        batch_Y = torch.from_numpy(Y_train[i : i + batch_size]).to(device).unsqueeze(1)\n",
    "\n",
    "        outputs = model(batch_X1, batch_X2)\n",
    "        outputs_acc.append(outputs.cpu().numpy())\n",
    "    outputs_acc = np.concatenate(outputs_acc, axis=0)\n",
    "    \n",
    "    train_Y = torch.from_numpy(Y_train).unsqueeze(1).cpu().numpy()\n",
    "\n",
    "df_train = pd.DataFrame(\n",
    "    {\n",
    "        \"similarity\": outputs_acc.flatten(),\n",
    "        \"plagio\": train_Y.flatten(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(df_train, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
